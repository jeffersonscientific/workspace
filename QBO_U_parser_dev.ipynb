{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCL stuff:\n",
    "#import Ngl, Nio\n",
    "import Nio\n",
    "#import pyncl\n",
    "#\n",
    "import pylab as plt\n",
    "import numpy\n",
    "#import scipy\n",
    "#\n",
    "import os,sys\n",
    "import time\n",
    "#import pathlib\n",
    "\n",
    "import getpass\n",
    "import subprocess\n",
    "import contextlib\n",
    "#\n",
    "# write a function to script this process (of extracting a layer from the model data).\n",
    "#. the data are some indexing of (time, altitude, lon, lat). This script will just focus on pulling\n",
    "#. a complete altitude layer, and from that only the pressure (['U']) variable. We'll re-dim a little\n",
    "#. bit, since we're just taking the one variable.\n",
    "#\n",
    "# NOTE: for now, let's skip the template file. It's a pain to validate, and may not really save us any time\n",
    "#. anyway.\n",
    "#def get_U_from_QBO_layer(layer_index=0, fpathname_src='', fpath_dest='', fname_dest=None,\n",
    "#                         fpathname_template=None, kt_0=0, kt_max=None):\n",
    "def copy_U_from_QBO_layer(layer_index=0, fpathname_src='', fpath_dest='', fname_dest=None, batch_size=None,\n",
    "                         kt_0=0, kt_max=None, verbose=0):\n",
    "\n",
    "\n",
    "    '''\n",
    "    #\n",
    "    # keep it simple for now. This script will basically do one job with only a few options.\n",
    "    # Variables:\n",
    "    # @layer_index: layer index to extract\n",
    "    # @fnamename_src: full path abnd filename of source data file\n",
    "    # @fpath_dest: output data file path. just the path; we want to allow for dynamic filename construction.\n",
    "    # @fname_dest: output data filename\n",
    "    # @fpathnamename_template: Full path an dname of a template file -- an empty (or otherwise intialized)\n",
    "    #. file with the right dimensinos, etc.\n",
    "    #.  writing the empty file seems to take a long, long time, so this is probably a reasonable way to save time.\n",
    "    # @kt_0, @kt_max: start and stop time indices. They will default to 0, and {max}\n",
    "    # \n",
    "    ''' \n",
    "    #\n",
    "    if fpathname_src is None:\n",
    "        fpathname_in = \"U_V_T_Z3_plWACCMSC_CTL_122.cam.h2.0001-0202.nc\"\n",
    "    if fpath_out is None:\n",
    "        fpath_out = ''\n",
    "    #\n",
    "    # fname: we'll handle it later... Same for fname_template, kt_max\n",
    "    #\n",
    "    # fname_out template:\n",
    "    # filo = \"U_10_QBO_\" + dum + \".nc\"\n",
    "    # (but we need to know more before we can )\n",
    "    #\n",
    "#     # try to validate the file. Just wrap this whole thing in a try, except. if we get an exception, \n",
    "#     #. we just (re-) create the file from scratch.\n",
    "#     with contextlib.closing(Nio.open_file(fpathname_src, 'r')) as fin:\n",
    "#         if not fpathname_template is None:\n",
    "#             try:\n",
    "#                 with contextlib.closing(Nio.open_file(fpathname_template), 'r') as f_temp:\n",
    "#                     #\n",
    "#                     # do we have a 'U' variable? We'll check the size. if the variable does not exist,\n",
    "#                     #. we'll throw an excetion anyway.\n",
    "#                     if numpy.shape(fin.variables['U']) != numpy.shape(f_temp.variables['U']):\n",
    "#                         raise Exception('Shapes of variables[U] are not consistent')\n",
    "#                     #\n",
    "#                     # there are probably more efficient ways to do this, but this is logically very solid.\n",
    "#                     #for ky,val in f_temp.dimensions.items():\n",
    "#                     for ky in f_temp.variables['U'].dimensions:\n",
    "#                         # check all dimensions, or just the ones we need?\n",
    "#                         if not fin.dimensions[ky] == f_temp.dimensikons[ky]:\n",
    "#                         #if not (ky in fin.dimensions.keys() and fin.dimensions[ky]==val):\n",
    "#                             raise Exception('Dimensions of output template do not match input')\n",
    "#                         #\n",
    "#             except:\n",
    "#                 print('Excepting on template file validation')\n",
    "#                 fpathname_template = None\n",
    "#                 #\n",
    "#             #\n",
    "    # create the output file:\n",
    "    # \n",
    "    with contextlib.closing(Nio.open_file(input_file_path, 'r')) as fin:\n",
    "        # time dimension size:\n",
    "        # we can get the full dimension size, if we are going to write the whole lot;\n",
    "        # otherwise, maybe just a subset?\n",
    "        n_time = fin.dimensions['time']\n",
    "        if batch_size is None:\n",
    "            batch_size=int(n_time/50)\n",
    "        #\n",
    "        if fname_dest is None or fname_dest='':\n",
    "            fname_dest = 'U_{}_QBO_k{}.nc'.format(fin.variables['lev_p'][layer_index], layer_index)\n",
    "        #\n",
    "        os.system('rm {}'.format(output_file_path))\n",
    "        if verbose: print('** DEBUG: open output file...')\n",
    "        with contextlib.closing(Nio.open_file(output_file_path, 'c')) as fout:\n",
    "            #\n",
    "            fout.create_dimension('time', n_time)\n",
    "            fout.create_dimension('lat', fin.dimensions['lat'])\n",
    "            fout.create_dimension('lon', fin.dimensions['lon'])\n",
    "            if verbose: print('** DEBUG: dimensions created: {}'.format(time.time()-t0))\n",
    "            #\n",
    "            # set the dimension variable values as well:\n",
    "            # NOTE: this step may not be necessary; these variables might be brought along by\n",
    "            #. the principal data, since those data have lat, lon, time listed as their dimensions.\n",
    "            for v_name in ('lat', 'lon', 'time'):\n",
    "                fout.create_variable(v_name, 'f', (v_name, ) )\n",
    "                fout.variables[v_name][:] = fin.variables[v_name]\n",
    "                #\n",
    "                if verbose: print('** DEBUG: var {} craeted'.format(v_name))\n",
    "            if verbose: print('** DEBUG: variables created (cumulative time): {}'.format(time.time()-t0))\n",
    "            #\n",
    "            fout.create_variable('U','f',('time','lat','lon'))\n",
    "            setattr(fout.variables['U'], 'standard_name', 'pressure')\n",
    "            setattr(fout.variables['U'], 'units', 'kPa')\n",
    "            if verbose: ('** DEBUG: variagble[U] created (cum time): {}'.format(time.time()-t0))\n",
    "            #\n",
    "            # NOTE: the .set_value() syntax is required for scaler, non-indexed values (or so I have read).\n",
    "            #. we can also use it for arrays, but only if we are assigning the whole value -- in other words, the \n",
    "            #. dimensinos must match. (this works if dim(udum)==dim(fout)). I assume the exception is if the output\n",
    "            #. dimension is undefined.\n",
    "            #\n",
    "            #fout.variables['u'].assign_value(udum)        # this works if dimensions align\n",
    "            #fout.variables['u'][0:len(udum)] = udum      # use this for partial assignment (note, i think this does allow \n",
    "            #                                            # (aka, will expand) for overflow -- [k,j] > len(fout.variable) )\n",
    "            #\n",
    "            if verbose: print('file created: {}'.format(time.time()-t0))\n",
    "            #\n",
    "            # now write file:\n",
    "            for j,k in enumerate(range(0, fin.dimensions['time'], batch_sizee)):\n",
    "                #print('** ** [{}:{}]'.format(k, k+batch_size_write))\n",
    "                #\n",
    "                # remember, our read-data are like:\n",
    "                # udum = fin.variables['U'][0:batch_size, 2,:,:]\n",
    "                # and we're making out output file more or less a mirror of that:\n",
    "                # note: we never explicilty store the data in a local variable; the memory footprint\n",
    "                #. is determined entirely by the NetCDF class, so really we can probably do this in one batch...\n",
    "                #  unless we want to parallelize, in which case we can run each of thsed batches an a Process() thread,\n",
    "                # in a Queue(), Pool(), etc.\n",
    "                t1=t2\n",
    "                t2 = time.time()\n",
    "                k1 = min(k+batch_size, n_time)\n",
    "                #\n",
    "                if verbose: print('begin k={}/{} batches [{}:{}]/{} :: {}.'.format(j, n_batches, k, k1, n_time, t2-t1))\n",
    "                #\n",
    "                #print('*** k:k1: {}:{}'.format(k,k1))\n",
    "                fout.variables['U'][k:k1] = fin.variables['U'][k:k1, 2,:,:]\n",
    "            #\n",
    "        #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test_file.nc'\n",
    "os.system('rm {}'.format(fname))\n",
    "with contextlib.closing(Nio.open_file(fname, 'c')) as fout:\n",
    "    fout.create_dimension('lat', 100)\n",
    "    fout.create_dimension('lon', 100)\n",
    "    #\n",
    "    fout.create_variable('U', 'd', ('lat', 'lon'))\n",
    "#\n",
    "with contextlib.closing(Nio.open_file(fname,'r')) as fin:\n",
    "    print('** dims: ', fin.dimensions)\n",
    "    #\n",
    "with contextlib.closing(Nio.open_file(fname, 'r+')) as fout:\n",
    "    #\n",
    "    fout.dimensions.update({'lon':200})\n",
    "    #\n",
    "with contextlib.closing(Nio.open_file(fname,'r')) as fin:\n",
    "    print('** dims: ', fin.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a':1, 'b':2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = Nio.open_file(fname,'r')\n",
    "\n",
    "print(fin.variables.keys())\n",
    "print(fin.variables['U'].dimensions)\n",
    "print('size: ', numpy.shape(fin.variables['U']))\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.closing(Nio.open_file('/scratch/yoder/U_V_T_Z3_plWACCMSC_CTL_122.cam.h2.0001-0202.nc', 'r')) as fin:\n",
    "    print('** ', fin.variables.keys())\n",
    "    print('** lev_p: ', [x for x in fin.variables['lev_p']])\n",
    "    print('** lev_p[2]: ', fin.variables['lev_p'][2])\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ncl_stable]",
   "language": "python",
   "name": "conda-env-ncl_stable-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
